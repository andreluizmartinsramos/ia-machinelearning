
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Final project}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd} 
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k}{import} \PY{n}{KMeans}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{decomposition} \PY{k}{import} \PY{n}{PCA}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{model\PYZus{}selection}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{classification\PYZus{}report}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{confusion\PYZus{}matrix}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LogisticRegression}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{DecisionTreeClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neighbors} \PY{k}{import} \PY{n}{KNeighborsClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{discriminant\PYZus{}analysis} \PY{k}{import} \PY{n}{LinearDiscriminantAnalysis}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import}  \PY{n}{BernoulliNB}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{SVC}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{AdaBoostClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neural\PYZus{}network} \PY{k}{import} \PY{n}{MLPClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{svm}\PY{p}{,} \PY{n}{datasets}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{GridSearchCV}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}124}]:} \PY{c+c1}{\PYZsh{}Importação do datasheet do exercício}
          \PY{n}{df\PYZus{}all} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{}Primeiro contato com datasheet, analisando o head, medias, desvios, max e mins.}
          \PY{n}{df\PYZus{}all}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}124}]:}                  id  radius\_mean  texture\_mean  perimeter\_mean    area\_mean  \textbackslash{}
          count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   
          mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   
          std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   
          min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   
          25\%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   
          50\%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   
          75\%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   
          max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   
          
                 smoothness\_mean  compactness\_mean  concavity\_mean  concave points\_mean  \textbackslash{}
          count       569.000000        569.000000      569.000000           569.000000   
          mean          0.096360          0.104341        0.088799             0.048919   
          std           0.014064          0.052813        0.079720             0.038803   
          min           0.052630          0.019380        0.000000             0.000000   
          25\%           0.086370          0.064920        0.029560             0.020310   
          50\%           0.095870          0.092630        0.061540             0.033500   
          75\%           0.105300          0.130400        0.130700             0.074000   
          max           0.163400          0.345400        0.426800             0.201200   
          
                 symmetry\_mean     {\ldots}       texture\_worst  perimeter\_worst  \textbackslash{}
          count     569.000000     {\ldots}          569.000000       569.000000   
          mean        0.181162     {\ldots}           25.677223       107.261213   
          std         0.027414     {\ldots}            6.146258        33.602542   
          min         0.106000     {\ldots}           12.020000        50.410000   
          25\%         0.161900     {\ldots}           21.080000        84.110000   
          50\%         0.179200     {\ldots}           25.410000        97.660000   
          75\%         0.195700     {\ldots}           29.720000       125.400000   
          max         0.304000     {\ldots}           49.540000       251.200000   
          
                  area\_worst  smoothness\_worst  compactness\_worst  concavity\_worst  \textbackslash{}
          count   569.000000        569.000000         569.000000       569.000000   
          mean    880.583128          0.132369           0.254265         0.272188   
          std     569.356993          0.022832           0.157336         0.208624   
          min     185.200000          0.071170           0.027290         0.000000   
          25\%     515.300000          0.116600           0.147200         0.114500   
          50\%     686.500000          0.131300           0.211900         0.226700   
          75\%    1084.000000          0.146000           0.339100         0.382900   
          max    4254.000000          0.222600           1.058000         1.252000   
          
                 concave points\_worst  symmetry\_worst  fractal\_dimension\_worst  \textbackslash{}
          count            569.000000      569.000000               569.000000   
          mean               0.114606        0.290076                 0.083946   
          std                0.065732        0.061867                 0.018061   
          min                0.000000        0.156500                 0.055040   
          25\%                0.064930        0.250400                 0.071460   
          50\%                0.099930        0.282200                 0.080040   
          75\%                0.161400        0.317900                 0.092080   
          max                0.291000        0.663800                 0.207500   
          
                 Unnamed: 32  
          count          0.0  
          mean           NaN  
          std            NaN  
          min            NaN  
          25\%            NaN  
          50\%            NaN  
          75\%            NaN  
          max            NaN  
          
          [8 rows x 32 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}171}]:} \PY{c+c1}{\PYZsh{}Datasheet só com as MEANS e Diagnostics}
          \PY{n}{df} \PY{o}{=} \PY{n}{df\PYZus{}all}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{11}\PY{p}{]}\PY{p}{]} 
          \PY{n}{df}\PY{p}{[}\PY{n}{df}\PY{o}{.}\PY{n}{values} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{}Foram evidenciados 78 casos com df.concavity\PYZus{}mean e df.concave points\PYZus{}mean com 0.00, prosseguimos as aferições assumindo que os valores são 0.0 mesmo e não se trata de dados faltantes.}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}171}]:}     diagnosis  radius\_mean  texture\_mean  perimeter\_mean  area\_mean  \textbackslash{}
          101         B        6.981         13.43           43.79      143.5   
          101         B        6.981         13.43           43.79      143.5   
          140         B        9.738         11.97           61.24      288.5   
          140         B        9.738         11.97           61.24      288.5   
          174         B       10.660         15.15           67.49      349.6   
          174         B       10.660         15.15           67.49      349.6   
          175         B        8.671         14.45           54.42      227.2   
          175         B        8.671         14.45           54.42      227.2   
          192         B        9.720         18.22           60.73      288.1   
          192         B        9.720         18.22           60.73      288.1   
          314         B        8.597         18.60           54.09      221.2   
          314         B        8.597         18.60           54.09      221.2   
          391         B        8.734         16.84           55.27      234.3   
          391         B        8.734         16.84           55.27      234.3   
          473         B       12.270         29.97           77.42      465.4   
          473         B       12.270         29.97           77.42      465.4   
          538         B        7.729         25.49           47.98      178.8   
          538         B        7.729         25.49           47.98      178.8   
          550         B       10.860         21.48           68.51      360.5   
          550         B       10.860         21.48           68.51      360.5   
          557         B        9.423         27.88           59.26      271.3   
          557         B        9.423         27.88           59.26      271.3   
          561         B       11.200         29.37           70.67      386.0   
          561         B       11.200         29.37           70.67      386.0   
          568         B        7.760         24.54           47.92      181.0   
          568         B        7.760         24.54           47.92      181.0   
          
               smoothness\_mean  compactness\_mean  concavity\_mean  concave points\_mean  \textbackslash{}
          101          0.11700           0.07568             0.0                  0.0   
          101          0.11700           0.07568             0.0                  0.0   
          140          0.09250           0.04102             0.0                  0.0   
          140          0.09250           0.04102             0.0                  0.0   
          174          0.08792           0.04302             0.0                  0.0   
          174          0.08792           0.04302             0.0                  0.0   
          175          0.09138           0.04276             0.0                  0.0   
          175          0.09138           0.04276             0.0                  0.0   
          192          0.06950           0.02344             0.0                  0.0   
          192          0.06950           0.02344             0.0                  0.0   
          314          0.10740           0.05847             0.0                  0.0   
          314          0.10740           0.05847             0.0                  0.0   
          391          0.10390           0.07428             0.0                  0.0   
          391          0.10390           0.07428             0.0                  0.0   
          473          0.07699           0.03398             0.0                  0.0   
          473          0.07699           0.03398             0.0                  0.0   
          538          0.08098           0.04878             0.0                  0.0   
          538          0.08098           0.04878             0.0                  0.0   
          550          0.07431           0.04227             0.0                  0.0   
          550          0.07431           0.04227             0.0                  0.0   
          557          0.08123           0.04971             0.0                  0.0   
          557          0.08123           0.04971             0.0                  0.0   
          561          0.07449           0.03558             0.0                  0.0   
          561          0.07449           0.03558             0.0                  0.0   
          568          0.05263           0.04362             0.0                  0.0   
          568          0.05263           0.04362             0.0                  0.0   
          
               symmetry\_mean  fractal\_dimension\_mean  
          101         0.1930                 0.07818  
          101         0.1930                 0.07818  
          140         0.1903                 0.06422  
          140         0.1903                 0.06422  
          174         0.1928                 0.05975  
          174         0.1928                 0.05975  
          175         0.1722                 0.06724  
          175         0.1722                 0.06724  
          192         0.1653                 0.06447  
          192         0.1653                 0.06447  
          314         0.2163                 0.07359  
          314         0.2163                 0.07359  
          391         0.1985                 0.07098  
          391         0.1985                 0.07098  
          473         0.1701                 0.05960  
          473         0.1701                 0.05960  
          538         0.1870                 0.07285  
          538         0.1870                 0.07285  
          550         0.1661                 0.05948  
          550         0.1661                 0.05948  
          557         0.1742                 0.06059  
          557         0.1742                 0.06059  
          561         0.1060                 0.05502  
          561         0.1060                 0.05502  
          568         0.1587                 0.05884  
          568         0.1587                 0.05884  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}126}]:} \PY{c+c1}{\PYZsh{}Aprofundando os entendimentos dos malignos, iniciando por análise exploratória plotando todos os histogramas das 10 vars.}
          \PY{n}{dfM} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{df}\PY{o}{.}\PY{n}{diagnosis} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{18}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{radius\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Radius}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{texture\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Texture}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{perimeter\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Perimeter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{area\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Area}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{smoothness\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Smoothness}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{compactness\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Compactness}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{concavity\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Concavity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{concave points\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concave points Compactness}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{symmetry\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Symmetry}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfM}\PY{o}{.}\PY{n}{fractal\PYZus{}dimension\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Fractal Dimension}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}126}]:} Text(0.5,1,'Fractal Dimension')
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_3_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}127}]:} \PY{c+c1}{\PYZsh{}Aprofundando os entendimentos dos benígnos, iniciando por análise exploratória plotando todos os histogramas das 10 vars.}
          \PY{n}{dfB} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{df}\PY{o}{.}\PY{n}{diagnosis} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{18}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{radius\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Radius}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{texture\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Texture}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{perimeter\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Perimeter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{area\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Area}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{smoothness\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Smoothness}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{compactness\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Compactness}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{concavity\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Concavity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{concave points\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concave points Compactness}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{symmetry\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Symmetry}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dfB}\PY{o}{.}\PY{n}{fractal\PYZus{}dimension\PYZus{}mean}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Fractal Dimension}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}127}]:} Text(0.5,1,'Fractal Dimension')
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_4_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}128}]:} \PY{c+c1}{\PYZsh{} Avaliando os histogramas consegui compreender que há variáveis com mais impacto na categorização de \PYZsq{}B\PYZsq{} ou \PYZsq{}M\PYZsq{} }
          \PY{c+c1}{\PYZsh{} É possível entender por meio de suas frequencias e disparidade em cada caso. }
          \PY{c+c1}{\PYZsh{} Variáveis excluídas: Com base na redundância de aparições tanto no \PYZsq{}B\PYZsq{} quanto no \PYZsq{}M\PYZsq{}, por exemplo:}
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{} Temos @MeanConcavity com +300f entre [0.0:0.1] como \PYZsq{}B\PYZsq{} e em \PYZsq{}M\PYZsq{} temos cerca 150f nesse range, tendo \PYZsq{}B\PYZsq{} quanto \PYZsq{}M\PYZsq{} no range de [0.1:0.3].}
          \PY{c+c1}{\PYZsh{} Usando o critério a cima foi cortado algumas variáveis que apresentam menos relação com o resultado.}
          \PY{c+c1}{\PYZsh{} Do mesmo modo temos @MeanSymmetry com um range grande de frequência tanto no \PYZsq{}B\PYZsq{} quanto no \PYZsq{}M\PYZsq{}}
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{} Diferente do @ConcavePointsCompactness, onde temos um range decrescente de \PYZsq{}B\PYZsq{} [0.0:0.08] e \PYZsq{}M\PYZsq{} [\PYZti{}0.02:0.2], ou seja, }
          \PY{c+c1}{\PYZsh{} temos um grande número de +0.08 caracterizado como \PYZsq{}M\PYZsq{} logo utilizaremos essa variável para as predições acreditando ser um bom splitpoint. }
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{} Variáveis escolhidas para aprofundamento: @MeanRadius \PYZhy{} @ConcavePointsCompactness \PYZhy{} @MeanPerimeter \PYZhy{} @MeanArea}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}129}]:} \PY{n}{df}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}129}]:} Index(['diagnosis', 'radius\_mean', 'texture\_mean', 'perimeter\_mean',
                 'area\_mean', 'smoothness\_mean', 'compactness\_mean', 'concavity\_mean',
                 'concave points\_mean', 'symmetry\_mean', 'fractal\_dimension\_mean'],
                dtype='object')
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}130}]:} \PY{c+c1}{\PYZsh{} Variáveis escolhidas manualmente para aprofundamento: @MeanRadius \PYZhy{} @ConcavePointsCompactness \PYZhy{} @MeanPerimeter \PYZhy{} @MeanArea}
          
          \PY{n}{df}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diagnosis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diagnosis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diagnosis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diagnosis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}130}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x20221a50438>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_7_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_7_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_7_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_7_4.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Há um número considerável de outliers, porém como são casos de doenças comprovados e tratando\PYZhy{}se de doenças, }
         \PY{c+c1}{\PYZsh{} mesmo que sejam anomalias distintas devem ser levadas em consideração para evitar Falso/(Positivo\PYZhy{}Negativo). }
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}131}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{18}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{radius\PYZus{}mean}\PY{p}{,}\PY{n}{df}\PY{o}{.}\PY{n}{diagnosis}\PY{p}{,} \PY{n}{s} \PY{o}{=} \PY{l+m+mi}{80}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{concave points\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{df}\PY{o}{.}\PY{n}{diagnosis}\PY{p}{,} \PY{n}{s} \PY{o}{=} \PY{l+m+mi}{80}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{perimeter\PYZus{}mean}\PY{p}{,}\PY{n}{df}\PY{o}{.}\PY{n}{diagnosis}\PY{p}{,} \PY{n}{s} \PY{o}{=} \PY{l+m+mi}{80}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{area\PYZus{}mean}\PY{p}{,}\PY{n}{df}\PY{o}{.}\PY{n}{diagnosis}\PY{p}{,} \PY{n}{s} \PY{o}{=} \PY{l+m+mi}{80}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}131}]:} <matplotlib.collections.PathCollection at 0x202227f7c18>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_9_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}133}]:} \PY{c+c1}{\PYZsh{}Preparando o Datasheet para montar o X excluindo apenas o Diagnostics que será nosso Y ao longo do projeto}
          \PY{n}{dfAll} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} As 4 variáveis escolhidas apresentam movimentos matemáticos muitos parecidos, ou seja, não são variáveis tão determinante.}
          \PY{c+c1}{\PYZsh{} Evidenciada a insatisfação já na etapa exploratória em relação às variáveis escolhidas, utilizamos o Profiling paraentender as }
          \PY{c+c1}{\PYZsh{} corelação entre as variáveis, buscando aumentar a accuracy por meio de variáveis mais determinantes}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}172}]:} \PY{o}{!}pip install pandas\PYZhy{}profiling
          
          \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{import} \PY{n+nn}{pandas\PYZus{}profiling}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          
          \PY{n}{pandas\PYZus{}profiling}\PY{o}{.}\PY{n}{ProfileReport}\PY{p}{(}\PY{n}{dfAll}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Requirement already satisfied: pandas-profiling in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (1.4.1)
Requirement already satisfied: pandas>=0.19 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from pandas-profiling) (0.23.0)
Requirement already satisfied: matplotlib>=1.4 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from pandas-profiling) (2.2.2)
Requirement already satisfied: six>=1.9 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from pandas-profiling) (1.11.0)
Requirement already satisfied: jinja2>=2.8 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from pandas-profiling) (2.10)
Requirement already satisfied: python-dateutil>=2.5.0 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from pandas>=0.19->pandas-profiling) (2.7.3)
Requirement already satisfied: pytz>=2011k in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from pandas>=0.19->pandas-profiling) (2018.4)
Requirement already satisfied: numpy>=1.9.0 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from pandas>=0.19->pandas-profiling) (1.14.3)
Requirement already satisfied: cycler>=0.10 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from matplotlib>=1.4->pandas-profiling) (0.10.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from matplotlib>=1.4->pandas-profiling) (2.2.0)
Requirement already satisfied: kiwisolver>=1.0.1 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from matplotlib>=1.4->pandas-profiling) (1.0.1)
Requirement already satisfied: MarkupSafe>=0.23 in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from jinja2>=2.8->pandas-profiling) (1.0)
Requirement already satisfied: setuptools in c:\textbackslash{}users\textbackslash{}pichau\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas-profiling) (39.1.0)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
distributed 1.21.8 requires msgpack, which is not installed.
You are using pip version 10.0.1, however version 18.0 is available.
You should consider upgrading via the 'python -m pip install --upgrade pip' command.

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}172}]:} <pandas\_profiling.ProfileReport at 0x2021f2c9240>
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}179}]:} \PY{c+c1}{\PYZsh{} Criando nossos Labels(Y), tivemos que binarizar o \PYZsq{}B\PYZsq{} e \PYZsq{}M\PYZsq{} para plotagens posteriores.}
          \PY{n}{dfTarget} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
          \PY{n}{dfTarget} \PY{o}{=} \PY{n}{dfTarget}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
          \PY{n}{dfTarget}\PY{p}{[}\PY{n}{dfTarget}\PY{o}{==}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
          \PY{n}{dfTarget}\PY{p}{[}\PY{n}{dfTarget}\PY{o}{==}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0}
\end{Verbatim}


    st = StandardScaler() pca = PCA(n\_components=2)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}180}]:} \PY{c+c1}{\PYZsh{} Entendimento da BigPicture, após passar para escala de 0,1 (StandardScaler), aplicamos o PCA para plotagens com 2 componetes e }
          \PY{c+c1}{\PYZsh{} vizualição por meio de dispersão, tentando aplicar o Kmeans para tentar descobrir alguma comportamento clusterizado das variáveis.}
          \PY{n}{st} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
          \PY{n}{pca} \PY{o}{=} \PY{n}{PCA}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
          
          \PY{n}{st}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{dfAll}\PY{p}{)}
          \PY{n}{dfAll} \PY{o}{=} \PY{n}{st}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{dfAll}\PY{p}{)}
          
          \PY{n}{pca}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{dfAll}\PY{p}{)}
          \PY{n}{dfDataPCA} \PY{o}{=} \PY{n}{pca}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{dfAll}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}182}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{9}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{dfTarget}\PY{p}{,} \PY{n}{edgecolors}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Foi possível observar uma divisão clara na dispersão do \PYZsq{}B\PYZsq{} e \PYZsq{}M\PYZsq{}, porém ainda há uma linha de confusão que intercciona vários casos, }
          \PY{c+c1}{\PYZsh{} sendo este o principal motivo de perda de acurácia na predição.}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}182}]:} <matplotlib.collections.PathCollection at 0x20225d300f0>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}183}]:} \PY{n}{kmeans} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{kmeans}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{dfData}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}183}]:} KMeans(algorithm='auto', copy\_x=True, init='k-means++', max\_iter=300,
              n\_clusters=2, n\_init=10, n\_jobs=1, precompute\_distances='auto',
              random\_state=None, tol=0.0001, verbose=0)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}184}]:} \PY{n}{preds\PYZus{}kmeans} \PY{o}{=} \PY{n}{kmeans}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{dfData}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}186}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{20}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{]}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{s} \PY{o}{=} \PY{l+m+mi}{90}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribuição dos dados escalados após PCA(2)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{n}{dfTarget}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Accent}\PY{p}{,} \PY{n}{s} \PY{o}{=} \PY{l+m+mi}{90}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribuição real dos dados}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{dfDataPCA}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{n}{preds\PYZus{}kmeans}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Accent}\PY{p}{,} \PY{n}{s}\PY{o}{=} \PY{l+m+mi}{90}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribuição dos dados via K\PYZhy{}means(2)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} A clusterização está muito generalizada, com baixo índice visual de precisão como podemos ver no 3º quadro}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}191}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neighbors} \PY{k}{import} \PY{n}{KNeighborsClassifier}
          
          \PY{c+c1}{\PYZsh{} Normalização e preprocessamento dos dados [Somente nas MEANS \PYZhy{} dfAll]}
          \PY{n}{st}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{dfAll}\PY{p}{)}
          \PY{n}{dfAllSS} \PY{o}{=} \PY{n}{st}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{dfAll}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{}aplicando PCA em cima dos datos Standartizados (Porém não foi utilizado, pois decaiu muito o rendimento dos testes)}
          \PY{n}{pca} \PY{o}{=} \PY{n}{PCA}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{pca}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{dfAllSS}\PY{p}{)}
          \PY{n}{dfAllSSPCA} \PY{o}{=} \PY{n}{pca}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{dfAllSS}\PY{p}{)}
          
          \PY{n}{Y} \PY{o}{=} \PY{n}{dfTarget}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{X} \PY{o}{=} \PY{n}{dfAllSS}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}192}]:} \PY{c+c1}{\PYZsh{} Machine Learning Algoritmos}
          \PY{n}{models} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          \PY{n}{models}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{KNeighborsClassifier......:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{n}{models}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DecisionTreeClassifier....:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{n}{models}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RandomForestClassifier....:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{n}{models}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MLPClassifier.............:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{MLPClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{n}{models}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SVM.......................:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}193}]:} \PY{c+c1}{\PYZsh{}Parâmetros para todos os Machine Learning Models}
          \PY{n}{seed} \PY{o}{=} \PY{l+m+mi}{7}
          \PY{n}{scoring} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}
          
          \PY{c+c1}{\PYZsh{}Avaliação para cada modelo escolhido}
          \PY{n}{results} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          \PY{n}{names} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{model} \PY{o+ow}{in} \PY{n}{models}\PY{p}{:}
              \PY{n}{kfold} \PY{o}{=} \PY{n}{model\PYZus{}selection}\PY{o}{.}\PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{seed}\PY{p}{)}
              \PY{n}{cv\PYZus{}results} \PY{o}{=} \PY{n}{model\PYZus{}selection}\PY{o}{.}\PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{kfold}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{n}{scoring}\PY{p}{)}
              \PY{n}{results}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{cv\PYZus{}results}\PY{p}{)}
              \PY{n}{names}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{name}\PY{p}{)}
              \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{ }\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s2}{ (}\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s2}{)}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{name}\PY{p}{,} \PY{n}{cv\PYZus{}results}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cv\PYZus{}results}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{n}{msg}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
KNeighborsClassifier{\ldots}: 0.938793 (0.040711)
DecisionTreeClassifier{\ldots}: 0.921305 (0.061561)
RandomForestClassifier{\ldots}: 0.942611 (0.055778)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
MLPClassifier{\ldots}: 0.950985 (0.043263)
SVM{\ldots}: 0.940579 (0.063118)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}195}]:} \PY{c+c1}{\PYZsh{} Cosidero boas acurácias que os algoritmos conseguirem por meio das 10 means, porém tratando\PYZhy{}se de quase 600 amostragens e }
          \PY{c+c1}{\PYZsh{} situações determinísticas surgiu a ideia de aprofundar\PYZhy{}se no nosso melhor resultado MLPClassifier}
          
          \PY{c+c1}{\PYZsh{}KNeighborsClassifier......: 0.938793 (0.040711)}
          \PY{c+c1}{\PYZsh{}DecisionTreeClassifier....: 0.921305 (0.061561)}
          \PY{c+c1}{\PYZsh{}RandomForestClassifier....: 0.942611 (0.055778)}
          \PY{c+c1}{\PYZsh{}MLPClassifier.............: 0.950985 (0.043263) \PYZlt{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{} Melhor resultado! Resolvemos ampliar para 30Vars (Means/Worst/Se)}
          \PY{c+c1}{\PYZsh{}SVM.......................: 0.940579 (0.063118)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}198}]:} \PY{c+c1}{\PYZsh{} Utilizando o GRIDSEARCHCV para procurar os melhores hiperparâmetros considerando os melhores score de cara pacote passado:}
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{} parameters = \PYZob{}\PYZsq{}kernel\PYZsq{}:(\PYZsq{}linear\PYZsq{}, \PYZsq{}rbf\PYZsq{}), \PYZsq{}C\PYZsq{}:[0.01, 0.1, 1.0, 10]\PYZcb{} }
          \PY{c+c1}{\PYZsh{} parameters = \PYZob{}\PYZsq{}n\PYZus{}neighbors\PYZsq{}: [1, 5, 10, 20, 50]\PYZcb{} }
          \PY{c+c1}{\PYZsh{} parameters = \PYZob{}\PYZsq{}n\PYZus{}estimators\PYZsq{}: [10], \PYZsq{}max\PYZus{}depth\PYZsq{}: [100] \PYZcb{}}
          \PY{c+c1}{\PYZsh{} parameters = \PYZob{}\PYZsq{}hidden\PYZus{}layer\PYZus{}sizes\PYZsq{}: [(5,),(10,),(30,),(45,),(50,),(100,),(300,)] \PYZcb{}}
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{} Não entendi porque mas todos caíram cerca de 1\PYZpc{} em relação ao teste anterior definidos com 20 Folds e valores default.}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}199}]:} \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{]}\PY{p}{\PYZcb{}} 
          
          \PY{n}{svc} \PY{o}{=} \PY{n}{svm}\PY{o}{.}\PY{n}{SVC}\PY{p}{(}\PY{p}{)}
          \PY{n}{clf} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{svc}\PY{p}{,} \PY{n}{parameters}\PY{p}{)}
          \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{)}
          
          \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Melhor parametro \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{ }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Melhor Score     \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{msg}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Melhor parametro --> \{'C': 10, 'kernel': 'rbf'\} 
Melhor Score     --> 0.9402460456942003

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}197}]:} \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}neighbors}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{]}\PY{p}{\PYZcb{}} 
          
          \PY{n}{kn} \PY{o}{=} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{p}{)}
          \PY{n}{clf} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{kn}\PY{p}{,} \PY{n}{parameters}\PY{p}{)}
          \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{)}
          
          \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Melhor parametro \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{ }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Melhor Score     \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{msg}\PY{p}{)}
              
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Melhor parametro --> \{'n\_neighbors': 5\} 
Melhor Score     --> 0.9367311072056239

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}151}]:} \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{10}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{100}\PY{p}{]} \PY{p}{\PYZcb{}}
          
          \PY{n}{rf} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
          \PY{n}{clf} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rf}\PY{p}{,} \PY{n}{parameters}\PY{p}{)}
          \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{)}
          
          \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Melhor parametro \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{ }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Melhor Score     \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{msg}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Melhor parametro --> \{'max\_depth': 100, 'n\_estimators': 10\} 
Melhor Score     --> 0.9367311072056239

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}152}]:} \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hidden\PYZus{}layer\PYZus{}sizes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{p}{)}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{p}{)}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{30}\PY{p}{,}\PY{p}{)}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{45}\PY{p}{,}\PY{p}{)}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{50}\PY{p}{,}\PY{p}{)}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,}\PY{p}{)}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{300}\PY{p}{,}\PY{p}{)}\PY{p}{]} \PY{p}{\PYZcb{}}
          
          \PY{n}{mlp} \PY{o}{=} \PY{n}{MLPClassifier}\PY{p}{(}\PY{p}{)}
          \PY{n}{clf} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{mlp}\PY{p}{,} \PY{n}{parameters}\PY{p}{)}
          \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{Y}\PY{p}{)}
          
          \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Melhor parametro \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{ }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Melhor Score     \PYZhy{}\PYZhy{}\PYZgt{} }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{msg}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Melhor parametro --> \{'hidden\_layer\_sizes': (100,)\} 
Melhor Score     --> 0.9420035149384886

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}Pichau\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}neural\_network\textbackslash{}multilayer\_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  \% self.max\_iter, ConvergenceWarning)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}200}]:} \PY{c+c1}{\PYZsh{} Não satisfeito, procuramos aumentar a accuracy e precision investindo na nossa melhor estratégia MLPClassifier}
          
          \PY{c+c1}{\PYZsh{} Todo o datasheet menos o \PYZdq{}id\PYZdq{} e \PYZdq{}Unnamed: 32\PYZdq{} que são inúteis.}
          \PY{n}{X} \PY{o}{=} \PY{n}{df\PYZus{}all}\PY{p}{[}\PY{n}{df\PYZus{}all}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}202}]:} \PY{c+c1}{\PYZsh{}Fatiamos em 35\PYZpc{} o size de Treino e Teste}
          \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}
              \PY{n}{X}\PY{p}{,}
              \PY{n}{Y}\PY{p}{,}
              \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{,}
              \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.32}
          \PY{p}{)}
          
          \PY{n}{X\PYZus{}train\PYZus{}scaler} \PY{o}{=} \PY{n}{st}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
          \PY{n}{X\PYZus{}test\PYZus{}scaler} \PY{o}{=} \PY{n}{st}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}206}]:} \PY{c+c1}{\PYZsh{} AJUSTANDO OS PARÂMETROS DO ALGORITMO DO MLPCLASS ADQUIRIDOS APÓS HORAS DE PROCESSAMENTO DO PERCEPTRON APICAMOS NO DATASHEET}
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{} Estrutura do Perceptron (ranges e pipelines):}
          \PY{c+c1}{\PYZsh{}}
          \PY{c+c1}{\PYZsh{}  @mlp\PYZus{}param\PYZus{}grid = [}
          \PY{c+c1}{\PYZsh{}     \PYZob{}}
          \PY{c+c1}{\PYZsh{}         \PYZsq{}preprocess\PYZsq{}: [Normalizer(), MinMaxScaler(), StandardScaler(), RobustScaler(), QuantileTransformer()],}
          \PY{c+c1}{\PYZsh{}         \PYZsq{}classification\PYZus{}\PYZus{}activation\PYZsq{}: [\PYZsq{}identity\PYZsq{}, \PYZsq{}logistic\PYZsq{}, \PYZsq{}tanh\PYZsq{}, \PYZsq{}relu\PYZsq{}],}
          \PY{c+c1}{\PYZsh{}         \PYZsq{}classification\PYZus{}\PYZus{}solver\PYZsq{}: [\PYZsq{}lbfgs\PYZsq{}, \PYZsq{}sgd\PYZsq{}, \PYZsq{}adam\PYZsq{}],}
          \PY{c+c1}{\PYZsh{}         \PYZsq{}classification\PYZus{}\PYZus{}random\PYZus{}state\PYZsq{}: 42,}
          \PY{c+c1}{\PYZsh{}         \PYZsq{}classification\PYZus{}\PYZus{}max\PYZus{}iter\PYZsq{}: range(1000, 10000, 1000),}
          \PY{c+c1}{\PYZsh{}         \PYZsq{}classification\PYZus{}\PYZus{}alpha\PYZsq{}: [1e\PYZhy{}4, 1e\PYZhy{}3, 0.01, 0.1, 1],}
          \PY{c+c1}{\PYZsh{}     \PYZcb{}}
          \PY{c+c1}{\PYZsh{}  ]}
          \PY{c+c1}{\PYZsh{}}
          
          
          \PY{c+c1}{\PYZsh{} O MODELO FINAL}
          \PY{n}{mlp} \PY{o}{=} \PY{n}{MLPClassifier}\PY{p}{(}
              \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,}
              \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
              \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{logistic}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{solver}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}
          \PY{p}{)}
          
          \PY{n}{mlp}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}scaler}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
          
          \PY{n}{mlp\PYZus{}predict} \PY{o}{=} \PY{n}{mlp}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaler}\PY{p}{)}
          \PY{n}{mlp\PYZus{}predict\PYZus{}proba} \PY{o}{=} \PY{n}{mlp}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaler}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MLP ACURÁCIA: }\PY{l+s+si}{\PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{mlp\PYZus{}predict}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MLP PRBABILIDADE (ROC CURVE): }\PY{l+s+si}{\PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{mlp\PYZus{}predict\PYZus{}proba}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MLP CLASSFICAÇÃO GERAL:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{mlp\PYZus{}predict}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MLP TOTAL TREINO: }\PY{l+s+si}{\PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{mlp}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}scaler}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MLP TOTAL TESTE: }\PY{l+s+si}{\PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{mlp}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaler}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
MLP ACURÁCIA: 99.45\%
MLP PRBABILIDADE (ROC CURVE): 99.86\%
MLP CLASSFICAÇÃO GERAL:

              precision    recall  f1-score   support

          0       0.99      1.00      1.00       119
          1       1.00      0.98      0.99        64

avg / total       0.99      0.99      0.99       183

MLP TOTAL TREINO: 98.45\%
MLP TOTAL TESTE: 99.45\%

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}204}]:} \PY{c+c1}{\PYZsh{} Com a matriz de confusão é possível perceber que só tivemos 1 Falso\PYZhy{}Positivo, }
          \PY{c+c1}{\PYZsh{} porém vale ressaltar que o algoritmo acertou TODOS os \PYZsq{}M\PYZsq{}.}
          
          \PY{n}{outcome\PYZus{}labels} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{df\PYZus{}all}\PY{o}{.}\PY{n}{diagnosis}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}
          
          \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}
              \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{mlp\PYZus{}predict}\PY{p}{)}\PY{p}{,}
              \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
              \PY{n}{fmt}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{d}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
              \PY{n}{xticklabels}\PY{o}{=}\PY{n}{outcome\PYZus{}labels}\PY{p}{,}
              \PY{n}{yticklabels}\PY{o}{=}\PY{n}{outcome\PYZus{}labels}
          \PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}204}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x2022806c128>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_31_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}205}]:} \PY{c+c1}{\PYZsh{}Outro modo interessante de tirar conclusões sobre a predição é a \PYZdq{}Curva ROC\PYZdq{}.}
          \PY{n}{fpr}\PY{p}{,} \PY{n}{tpr}\PY{p}{,} \PY{n}{thresholds} \PY{o}{=} \PY{n}{roc\PYZus{}curve}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{mlp\PYZus{}predict\PYZus{}proba}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{fpr}\PY{p}{,} \PY{n}{tpr}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{font.size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{12}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ROC curva MLPClassifier}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Taxa de falso/positivo (1 \PYZhy{} Especificidade)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Taxa de verdadeiro/positivo (Sensitividade)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_32_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
